{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOrmDwU68lj8YPF2ASMLteU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DhrumilBhatiya/Persist-Ventures/blob/main/Video_Recommendation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests\n",
        "!pip install flask pyngrok scikit-learn pandas requests\n",
        "!pip install Flask requests pandas scikit-learn\n",
        "!pip install requests Flask"
      ],
      "metadata": {
        "id": "7yXguoNs9D75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fetch Data From URL"
      ],
      "metadata": {
        "id": "BDcDyMQyP23T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Set the base URL for the SocialVerse API\n",
        "BASE_URL = \"https://api.socialverseapp.com\"\n",
        "HEADERS = {\"Flic-Token\": \"flic_6e2d8d25dc29a4ddd382c2383a903cf4a688d1a117f6eb43b35a1e7fadbb84b8\"}\n",
        "\n",
        "def get_data(endpoint, params=None):\n",
        "    \"\"\" Helper function to fetch data from API \"\"\"\n",
        "    response = requests.get(endpoint, headers=HEADERS, params=params)\n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Fetch all viewed posts\n",
        "viewed_posts = get_data(f\"{BASE_URL}/posts/view\", params={\"page\": 1, \"page_size\": 1000})\n",
        "liked_posts = get_data(f\"{BASE_URL}/posts/like\", params={\"page\": 1, \"page_size\": 1000})\n",
        "inspired_posts = get_data(f\"{BASE_URL}/posts/inspire\", params={\"page\": 1, \"page_size\": 1000})\n",
        "rated_posts = get_data(f\"{BASE_URL}/posts/rating\", params={\"page\": 1, \"page_size\": 1000})\n",
        "all_posts = get_data(f\"{BASE_URL}/posts/summary/get\", params={\"page\": 1, \"page_size\": 1000})\n",
        "users_data = get_data(f\"{BASE_URL}/users/get_all\", params={\"page\": 1, \"page_size\": 1000})"
      ],
      "metadata": {
        "id": "khlb0ZF1yVJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "177xrcbTduCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_dataframe(data):\n",
        "    return pd.DataFrame(data) if data else pd.DataFrame()\n",
        "\n",
        "viewed_df = to_dataframe(viewed_posts['posts'])\n",
        "liked_df = to_dataframe(liked_posts['posts'])\n",
        "inspired_df = to_dataframe(inspired_posts['posts'])\n",
        "rated_df = to_dataframe(rated_posts['posts'])\n",
        "all_posts_df = to_dataframe(all_posts['posts'])\n",
        "users_df = to_dataframe(users_data['users'])\n",
        "\n",
        "# Data Preprocessing: Normalize, Handle Missing Values, and Create Derived Features\n",
        "def preprocess_data(df):\n",
        "    df.fillna('', inplace=True)\n",
        "    df['category'] = df['category'].apply(lambda x: x.lower() if isinstance(x, str) else '')\n",
        "    return df\n",
        "\n",
        "viewed_df = preprocess_data(viewed_df)\n",
        "liked_df = preprocess_data(liked_df)\n",
        "inspired_df = preprocess_data(inspired_df)\n",
        "rated_df = preprocess_data(rated_df)\n",
        "all_posts_df = preprocess_data(all_posts_df)"
      ],
      "metadata": {
        "id": "qAnsysfpd2M-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Algorithm Development"
      ],
      "metadata": {
        "id": "tegm0KDkd6xd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Content-based filtering: Recommending based on categories and metadata similarity\n",
        "def content_based_recommendation(user_posts, all_posts_df):\n",
        "    all_posts_df['category_encoded'] = LabelEncoder().fit_transform(all_posts_df['category'])\n",
        "    user_posts['category_encoded'] = LabelEncoder().fit_transform(user_posts['category'])\n",
        "\n",
        "    user_profile = np.mean(user_posts['category_encoded'].values)\n",
        "    similarity_scores = cosine_similarity([user_profile], all_posts_df['category_encoded'].values.reshape(-1, 1))\n",
        "    all_posts_df['similarity'] = similarity_scores.flatten()\n",
        "\n",
        "    recommended_posts = all_posts_df.sort_values(by='similarity', ascending=False).head(10)\n",
        "    return recommended_posts[['post_id', 'similarity']]\n",
        "\n",
        "# Collaborative filtering: Using user ratings or interaction data to recommend\n",
        "def collaborative_filtering(user_id, all_posts_df, interactions_df):\n",
        "    user_interactions = interactions_df[interactions_df['user_id'] == user_id]\n",
        "\n",
        "    interaction_matrix = pd.pivot_table(interactions_df, values='rating', index='user_id', columns='post_id')\n",
        "    similarity_matrix = cosine_similarity(interaction_matrix.fillna(0))\n",
        "\n",
        "    user_index = interaction_matrix.index.get_loc(user_id)\n",
        "    similar_users = similarity_matrix[user_index]\n",
        "\n",
        "    recommended_posts = []\n",
        "    for i, similarity in enumerate(similar_users):\n",
        "        if similarity > 0.5:\n",
        "            recommended_posts.append(interaction_matrix.columns[i])\n",
        "\n",
        "    return all_posts_df[all_posts_df['post_id'].isin(recommended_posts)]\n",
        "\n",
        "# Hybrid recommendation (combining content-based and collaborative)\n",
        "def hybrid_recommendation(user_id, user_posts, all_posts_df, interactions_df):\n",
        "    content_recommendations = content_based_recommendation(user_posts, all_posts_df)\n",
        "    collaborative_recommendations = collaborative_filtering(user_id, all_posts_df, interactions_df)\n",
        "\n",
        "    combined_recommendations = pd.merge(content_recommendations, collaborative_recommendations, on='post_id', how='outer')\n",
        "    return combined_recommendations[['post_id', 'similarity']].head(10)\n"
      ],
      "metadata": {
        "id": "uWJZVd3syW-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation Metrics"
      ],
      "metadata": {
        "id": "HhB_p9vaeRJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import linear_model\n",
        "\n",
        "\n",
        "y_data = all_posts_df['rating_count']\n",
        "x_data = all_posts_df.iloc[:,6:8]\n",
        "\n",
        "#Split the all_posts_data for LinearRegression\n",
        "X_train, X_test,Y_train, Y_test = train_test_split(x_data, y_data,test_size=0.4,random_state=1)\n",
        "linear_regressor = linear_model.LinearRegression()\n",
        "linear_regressor.fit(X_train, Y_train)\n",
        "Y_pred = linear_regressor.predict(X_test)\n",
        "\n",
        "#Evalute Mean Absolute Error and Root mean square error\n",
        "def evaluate_recommendations(actual, predicted):\n",
        "    mae = mean_absolute_error(actual, predicted)\n",
        "    rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
        "    return mae, rmse\n",
        "\n",
        "mae, rmse = evaluate_recommendations(Y_test, Y_pred)\n",
        "print(f\"MAE: {mae}, RMSE: {rmse}\")\n"
      ],
      "metadata": {
        "id": "JYSUYIIH89K5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/feed', methods=['GET'])\n",
        "def get_recommended_posts():\n",
        "    username = request.args.get('username')\n",
        "    category_id = request.args.get('category_id')\n",
        "    mood = request.args.get('mood', None)\n",
        "\n",
        "    # Retrieve user posts based on username and category\n",
        "    user_posts = all_posts_df[all_posts_df['username'] == username]\n",
        "\n",
        "    if mood:\n",
        "        recommendations = hybrid_recommendation(username, user_posts, all_posts_df, rated_df)\n",
        "    else:\n",
        "        recommendations = recommendations = all_posts_df[all_posts_df['category'] == category_id].head(10)\n",
        "\n",
        "    return jsonify(recommendations.to_dict(orient='records'))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True,port=8000)\n"
      ],
      "metadata": {
        "id": "OjWlkvME85t4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}